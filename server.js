// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤– Ø§Ù„Ø¯Ù„Ù…Ø§ AI - Backend Server
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import express from 'express';
import cors from 'cors';
import multer from 'multer';
import 'dotenv/config';

const app = express();
const PORT = process.env.PORT || 3000;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
// ğŸ”§ Middleware
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
app.use(cors({
    origin: '*', // Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±
    methods: ['GET', 'POST', 'OPTIONS'],
    allowedHeaders: ['Content-Type', 'Authorization']
}));

app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Setup multer for file uploads (images)
const storage = multer.memoryStorage();
const upload = multer({ 
    storage: storage,
    limits: { fileSize: 10 * 1024 * 1024 }, // 10MB per file
    fileFilter: (req, file, cb) => {
        if (file.mimetype.startsWith('image/')) {
            cb(null, true);
        } else {
            cb(new Error('Only images are allowed'));
        }
    }
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
// ğŸ  Health Check
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
app.get('/', (req, res) => {
    res.json({
        status: 'online',
        service: 'Ø§Ù„Ø¯Ù„Ù…Ø§ AI Backend',
        version: '1.0.0',
        endpoints: {
            chat: 'POST /chat',
            health: 'GET /'
        }
    });
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
// ğŸ’¬ Chat Endpoint
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
app.post('/chat', upload.array('images', 10), async (req, res) => {
    try {
        const { message, history } = req.body;
        const images = req.files || [];

        console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
        console.log('ğŸ“¥ New Chat Request');
        console.log('Message:', message);
        console.log('Images:', images.length);
        console.log('History:', history ? JSON.parse(history).length + ' messages' : 'none');
        console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

        // Validate message
        if (!message && images.length === 0) {
            return res.status(400).json({
                error: 'ÙŠØ±Ø¬Ù‰ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø£Ùˆ ØµÙˆØ±Ø©'
            });
        }

        // Parse history
        let chatHistory = [];
        if (history) {
            try {
                chatHistory = JSON.parse(history);
            } catch (e) {
                console.warn('âš ï¸ Failed to parse history:', e.message);
            }
        }

        // Call OpenAI API if API key is available
        let aiResponse = '';
        
        if (!process.env.OPENAI_API_KEY) {
            console.error('âŒ OPENAI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Environment Variables');
            return res.status(500).json({
                error: 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª - ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
                details: 'OPENAI_API_KEY is missing'
            });
        }
        
        console.log('âœ… OPENAI_API_KEY Ù…ÙˆØ¬ÙˆØ¯');
        console.log('ğŸ“‹ PROMPT_ID:', process.env.OPENAI_PROMPT_ID || 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯');
        console.log('ğŸ“‹ MODEL:', process.env.MODEL || 'default');
        
        console.log('ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI...');
        aiResponse = await getOpenAIResponse(message, images, chatHistory);
        console.log('âœ… ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ù…Ù† OpenAI Ø¨Ù†Ø¬Ø§Ø­');

        // Return response
        res.json({
            response: aiResponse,
            timestamp: new Date().toISOString()
        });

        console.log('âœ… Response sent successfully');

    } catch (error) {
        console.error('âŒ Chat Error:', error);
        res.status(500).json({
            error: 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ',
            message: error.message
        });
    }
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
// ğŸ¤– OpenAI Integration
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
async function getOpenAIResponse(message, images, chatHistory = []) {
    const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
    const MODEL = process.env.MODEL || 'gpt-5';
    const PROMPT_ID = process.env.OPENAI_PROMPT_ID;
    const PROMPT_VERSION = process.env.OPENAI_PROMPT_VERSION || '2';

    console.log('ğŸ”§ [DEBUG] Starting getOpenAIResponse');
    console.log('ğŸ”§ [DEBUG] Model:', MODEL);
    console.log('ğŸ”§ [DEBUG] Message:', message);
    console.log('ğŸ”§ [DEBUG] Images count:', images.length);
    console.log('ğŸ”§ [DEBUG] History count:', chatHistory.length);
    console.log('ğŸ”§ [DEBUG] Using Prompt ID:', PROMPT_ID ? 'YES' : 'NO');

    // Ø¨Ù†Ø§Ø¡ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    const inputMessages = [];
    
    // Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ PROMPT_ID Ù†Ø¶ÙŠÙ developer prompt Ø¯Ø§Ø®Ù„ input
    if (!PROMPT_ID) {
        inputMessages.push({
            role: 'developer',
            content: [{
                type: 'input_text',
                text: `Ø£Ù†Øª "Ø§Ù„Ø¯Ù„Ù…Ø§ AI" - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù…Ù† Ø´Ø±ÙƒØ© ÙƒØ§Ø±Ù…Ø§Ø± Ø¨Ù…Ø¯ÙŠÙ†Ø© Ø¹Ø±Ø¹Ø± (Ø´Ù…Ø§Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©).

ğŸŒŠ Ù…Ù‡Ù…ØªÙƒ:
- Ø±Ø¯ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø´Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø¨Ø¯ÙˆÙŠØ© (Ø£Ù‡Ù„ Ø¹Ø±Ø¹Ø±) Ø¨Ø´ÙƒÙ„ Ù„Ø¨Ù‚ ÙˆÙˆØ§Ø¶Ø­
- Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ± Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØµÙÙ‡Ø§ Ø¨Ø§Ù„ØªÙØµÙŠÙ„
- Ù„Ø§ ØªØ°ÙƒØ± Ø£Ø¨Ø¯Ø§Ù‹ Ø£ÙŠ Ø´Ø±ÙƒØ§Øª Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø£Ø®Ø±Ù‰
- Ø£Ù†Øª "Ø§Ù„Ø¯Ù„Ù…Ø§ AI" ÙÙ‚Ø· Ù…Ù† Ø´Ø±ÙƒØ© ÙƒØ§Ø±Ù…Ø§Ø±

ğŸ’š Ø§Ù„Ø¯Ù„Ù…Ø§... Ø²Ø±Ø¹Ù‡Ø§ Ø·ÙŠØ¨ØŒ ÙˆØ®ÙŠØ±Ù‡Ø§ Ø¨Ø§Ù‚Ù`
            }]
        });
    }
    
    // Ø¥Ø¶Ø§ÙØ© Ø¢Ø®Ø± 10 Ø±Ø³Ø§Ø¦Ù„ Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®
    for (const msg of chatHistory.slice(-10)) {
        if (msg.role === 'user') {
            inputMessages.push({
                role: 'user',
                content: [{ type: 'input_text', text: msg.text || '' }]
            });
        } else if (msg.role === 'bot') {
            inputMessages.push({
                role: 'assistant',
                content: [{ type: 'output_text', text: msg.text || '' }]
            });
        }
    }
    
    // Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    const newContent = [];
    if (message) {
        newContent.push({ type: 'input_text', text: message });
    }
    
    // Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ± Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù€ GPT-5
    for (const image of (images || []).slice(0, 10)) {
        const base64Image = image.buffer.toString('base64');
        newContent.push({
            type: 'input_image',
            image_url: `data:${image.mimetype};base64,${base64Image}`
        });
        console.log('ğŸ–¼ï¸ [DEBUG] Added image:', image.mimetype);
    }
    
    inputMessages.push({
        role: 'user',
        content: newContent
    });

    // Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø·Ù„Ø¨
    const body = {
        model: MODEL,
        input: inputMessages,
        max_output_tokens: 4000, // Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø¶Ù…Ø§Ù† Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø±Ø¯
        reasoning: { effort: 'medium' }
    };

    // Ø¥Ø°Ø§ ÙƒØ§Ù† PROMPT_ID Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ù†Ø±Ø³Ù„Ù‡ ÙˆÙÙ‚ Ø¨Ù†ÙŠØ© responses API
    if (PROMPT_ID) {
        body.prompt = { id: PROMPT_ID, version: PROMPT_VERSION };
        body.store = true;
        body.include = [
            'reasoning.encrypted_content',
            'web_search_call.action.sources'
        ];
    }

    console.log('ğŸ“¤ [DEBUG] Request Body:', JSON.stringify(body, null, 2));

    // ğŸ”„ Retry Logic - 3 Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù…Ø¹ ØªØ£Ø®ÙŠØ± Ù…ØªØ²Ø§ÙŠØ¯
    const MAX_RETRIES = 3;
    let lastError = null;
    
    for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
        try {
            console.log(`ğŸ”„ [ATTEMPT ${attempt}/${MAX_RETRIES}] Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI...`);
            
            const resp = await fetch('https://api.openai.com/v1/responses', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${OPENAI_API_KEY}`
                },
                body: JSON.stringify(body)
            });

            console.log('ğŸ“¡ [DEBUG] Response Status:', resp.status);

            // Ø¥Ø°Ø§ ÙƒØ§Ù† 5xx (Server Error)ØŒ Ù†Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©
            if (resp.status >= 500 && resp.status < 600) {
                const errorText = await resp.text();
                console.error(`âŒ [ATTEMPT ${attempt}] Server Error ${resp.status}:`, errorText);
                lastError = new Error(`Server Error: ${resp.status}`);
                
                // Ø§Ù†ØªØ¸Ø± Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (2ØŒ 4ØŒ 8 Ø«ÙˆØ§Ù†ÙŠ)
                if (attempt < MAX_RETRIES) {
                    const delay = Math.pow(2, attempt) * 1000;
                    console.log(`â³ Ø§Ù†ØªØ¸Ø§Ø± ${delay/1000} Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©...`);
                    await new Promise(resolve => setTimeout(resolve, delay));
                    continue; // Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©
                }
            }

            // Ø¥Ø°Ø§ ÙƒØ§Ù† 4xx (Client Error)ØŒ Ù„Ø§ Ù†Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©
            if (!resp.ok) {
                const errorText = await resp.text();
                console.error('âŒ [DEBUG] API Error Response:', errorText);
                throw new Error(`GPT-5 API Error: ${resp.status} - ${errorText}`);
            }

            const data = await resp.json();
            console.log('ğŸ“¥ [DEBUG] Response Data:', JSON.stringify(data, null, 2));
            
            // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù€ output
            if (Array.isArray(data.output)) {
                for (const item of data.output) {
                    if (item.type === 'message' && Array.isArray(item.content)) {
                        for (const c of item.content) {
                            if (c.type === 'output_text' && c.text) {
                                console.log('âœ… [DEBUG] Found output_text:', c.text.substring(0, 100) + '...');
                                return c.text;
                            }
                        }
                    }
                }
            }
            
            // Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø©
            if (data.output_text) {
                console.log('âœ… [DEBUG] Found direct output_text');
                return data.output_text;
            }
            
            // Ù„Ù… Ù†Ø¬Ø¯ Ù†Øµ ÙÙŠ Ø§Ù„Ù€ response
            console.error('âŒ [DEBUG] No valid text found in response');
            console.error('âŒ [DEBUG] Full Response:', JSON.stringify(data, null, 2));
            throw new Error('No text found in AI response');
            
        } catch (error) {
            lastError = error;
            console.error(`âŒ [ATTEMPT ${attempt}] Error:`, error.message);
            
            // Ø¥Ø°Ø§ ÙƒØ§Ù† timeout Ø£Ùˆ network errorØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©
            if (attempt < MAX_RETRIES && (error.message.includes('timeout') || error.message.includes('fetch') || error.message.includes('Server Error'))) {
                const delay = Math.pow(2, attempt) * 1000;
                console.log(`â³ Ø§Ù†ØªØ¸Ø§Ø± ${delay/1000} Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©...`);
                await new Promise(resolve => setTimeout(resolve, delay));
                continue;
            }
            
            // Ø¥Ø°Ø§ ÙƒØ§Ù† client errorØŒ Ù„Ø§ Ù†Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©
            break;
        }
    }
    
    // ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª - Ù†Ø±Ù…ÙŠ error Ø¨Ø¯Ù„ fallback
    console.error('âŒ [FAILED] ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª');
    throw lastError || new Error('Failed to get AI response after all retries');
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
// âœ… No Fallback - Always use real AI or fail gracefully
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
// ğŸš€ Start Server
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
app.listen(PORT, () => {
    console.log('');
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
    console.log('ğŸŒŠ Ø§Ù„Ø¯Ù„Ù…Ø§ AI Backend Server');
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
    console.log(`ğŸš€ Server running on port ${PORT}`);
    console.log(`ğŸŒ Health: http://localhost:${PORT}/`);
    console.log(`ğŸ’¬ Chat: POST http://localhost:${PORT}/chat`);
    console.log('');
    console.log('ğŸ“Š Status:');
    console.log(`   AI Engine: ${process.env.OPENAI_API_KEY ? 'âœ… Active' : 'âš ï¸  Not configured'}`);
    console.log(`   Model: ${process.env.MODEL || 'default'}`);
    console.log('');
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
    console.log('');
});

// Handle uncaught errors
process.on('uncaughtException', (error) => {
    console.error('âŒ Uncaught Exception:', error);
});

process.on('unhandledRejection', (error) => {
    console.error('âŒ Unhandled Rejection:', error);
});

